{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício 07_03\n",
    "\n",
    "#### Juliana Carolina Thuler dos Santos\n",
    "\n",
    "## Exploração\n",
    "\n",
    "Utilizando o conjunto de dados de compras (`compra_online_treino.csv`), testar qual modelo (Regressão Logística, KNN e Árvore) se adaptará melhor a este conjunto de dados. Realizar o pré-processamento necessário para cada um, explicando o por quê desta decisão.\n",
    "\n",
    "PS: apesar do nomes do arquivo ser `compra_online_treino.csv`, separar em treino e teste, aplicando a metodologia que você julgar melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('compra_online_treino.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9247 entries, 0 to 9246\n",
      "Data columns (total 18 columns):\n",
      "Administrative             9173 non-null float64\n",
      "Administrative_Duration    9182 non-null float64\n",
      "Informational              9171 non-null float64\n",
      "Informational_Duration     9170 non-null float64\n",
      "ProductRelated             9173 non-null float64\n",
      "ProductRelated_Duration    9164 non-null float64\n",
      "BounceRates                9168 non-null float64\n",
      "ExitRates                  9166 non-null float64\n",
      "PageValues                 9177 non-null float64\n",
      "SpecialDay                 9187 non-null float64\n",
      "Month                      9174 non-null object\n",
      "OperatingSystems           9181 non-null float64\n",
      "Browser                    9186 non-null float64\n",
      "Region                     9184 non-null float64\n",
      "TrafficType                9193 non-null float64\n",
      "VisitorType                8075 non-null object\n",
      "Weekend                    9167 non-null float64\n",
      "Revenue                    9247 non-null bool\n",
      "dtypes: bool(1), float64(15), object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericas = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "             'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
    "             'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay']\n",
    "\n",
    "categoricas_num = ['OperatingSystems', 'Browser', 'Region', 'TrafficType', 'Weekend']\n",
    "\n",
    "categoricas_qlt = ['Month','VisitorType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "df_treino, df_teste = tts(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rl_treino = df_treino.copy()\n",
    "df_rl_teste = df_teste.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in numericas: #talvez seja uma informação útil\n",
    "#    print(len(df_rl_treino[df_rl_treino[col] == -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_rl_treino.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_rl_teste.isnull().sum()\n",
    "#df_rl_teste.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituir as numéricas faltantes com a média\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "si = SimpleImputer(strategy = 'median')\n",
    "df_rl_treino[numericas] = si.fit_transform(df_rl_treino[numericas])\n",
    "df_rl_teste[numericas] = si.transform(df_rl_teste[numericas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituir as categoricas numericas faltantes com a moda\n",
    "si_num = SimpleImputer(strategy = 'most_frequent')\n",
    "\n",
    "df_rl_treino[categoricas_num] = si_num.fit_transform(df_rl_treino[categoricas_num])\n",
    "df_rl_teste[categoricas_num] = si_num.transform(df_rl_teste[categoricas_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituir as categoricas qualitativas faltantes com valor diferente de qualquer um da amostra\n",
    "si_qlt = SimpleImputer(strategy = 'constant', fill_value = 'Missing')\n",
    "\n",
    "df_rl_treino[categoricas_qlt] = si_qlt.fit_transform(df_rl_treino[categoricas_qlt])\n",
    "df_rl_teste[categoricas_qlt] = si_qlt.transform(df_rl_teste[categoricas_qlt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformar as categoricas qualitativas em numericas\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "oe = OrdinalEncoder()\n",
    "\n",
    "df_rl_treino[categoricas_qlt] = oe.fit_transform(df_rl_treino[categoricas_qlt])\n",
    "df_rl_teste[categoricas_qlt] = oe.transform(df_rl_teste[categoricas_qlt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jtsantos\\my-venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\jtsantos\\my-venv\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(df_rl_treino.drop(columns = 'Revenue'),df_rl_treino[['Revenue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste = df_rl_teste.drop(columns = 'Revenue')\n",
    "y_teste = df_rl_teste[['Revenue']]\n",
    "\n",
    "pred = lr.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score as asc\n",
    "round(asc(pred,y_teste),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1547 18 42 243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_teste['Revenue'].values, pred).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerações\n",
    "\n",
    "Como sklearn não considera variáveis faltantes ou do tipo texto, fiz as transformações necessárias.\n",
    "Para as numéricas faltantes considerei a mediana (uma vez que os valores máximos apresentavam-se muito distante da mediana, o que com certeza afetaria a média), e para as categóricas numéricas faltantes considerei a moda. \n",
    "\n",
    "As categóricas qualitativas, por apresentarem um número muito grande de faltantes, preferi transformar as faltantes em um valor diferente. Após tal transformação, transformei em numéricas. \n",
    "\n",
    "Pelos cálculos matemáticos envolvidos na regressão logística, considerando o número de euler elevado a um valor negativo, e o valor em questão considerar fatores de multiplicação em função da importância das variáveis,~não acreditei ser necessário mudar as escalas nos valores numéricos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessitaria realizar todas as transformações já realizadas até então nos df's para Regressão Logística\n",
    "df_knn_treino = df_rl_treino.copy()\n",
    "df_knn_teste = df_rl_teste.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jtsantos\\my-venv\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#realização de knn sem normalizar as colunas de variáveis numéricas e categoricas numericas\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(df_knn_treino.drop(columns = 'Revenue'),df_knn_treino[['Revenue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste = df_knn_teste.drop(columns = 'Revenue')\n",
    "y_teste = df_knn_teste[['Revenue']]\n",
    "\n",
    "pred = knn.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acurácia\n",
    "round(asc(pred,y_teste),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1518 47 199 86\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_teste['Revenue'].values, pred).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizar as colunas de variáveis numéricas e categoricas numericas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "df_knn_treino[numericas] = mms.fit_transform(df_knn_treino[numericas])\n",
    "df_knn_teste[numericas] = mms.transform(df_knn_teste[numericas])\n",
    "\n",
    "df_knn_treino[categoricas_num] = mms.fit_transform(df_knn_treino[categoricas_num])\n",
    "df_knn_teste[categoricas_num] = mms.transform(df_knn_teste[categoricas_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jtsantos\\my-venv\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(df_knn_treino.drop(columns = 'Revenue'),df_knn_treino[['Revenue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste = df_knn_teste.drop(columns = 'Revenue')\n",
    "y_teste = df_knn_teste[['Revenue']]\n",
    "\n",
    "pred = knn.predict(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acurácia\n",
    "round(asc(pred,y_teste),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1555 10 57 228\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_teste['Revenue'].values, pred).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Considerações\n",
    "\n",
    "Nesse caso, pudemos perceber a importância de normalizar as colunas da amostra uma vez que o KNN considera uma equeação de \"distância entre pontos\" e, nesse caso, as amplitudes podem alterar sigficativamente nossos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#considerar as manipulações realizadas para a regressão logística\n",
    "df_add_treino = df_rl_treino.copy()\n",
    "df_add_teste = df_rl_teste.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidade:  3\n",
      "Ácurácia:  0.97\n",
      "TN, FP, FN, TP:  1547 18 46 239\n",
      "\n",
      "\n",
      "Profundidade:  4\n",
      "Ácurácia:  0.97\n",
      "TN, FP, FN, TP:  1547 18 40 245\n",
      "\n",
      "\n",
      "Profundidade:  5\n",
      "Ácurácia:  0.97\n",
      "TN, FP, FN, TP:  1553 12 43 242\n",
      "\n",
      "\n",
      "Profundidade:  6\n",
      "Ácurácia:  0.96\n",
      "TN, FP, FN, TP:  1545 20 46 239\n",
      "\n",
      "\n",
      "Profundidade:  7\n",
      "Ácurácia:  0.96\n",
      "TN, FP, FN, TP:  1543 22 50 235\n",
      "\n",
      "\n",
      "Profundidade:  8\n",
      "Ácurácia:  0.95\n",
      "TN, FP, FN, TP:  1539 26 58 227\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "for i in np.arange(3,9,1):\n",
    "    \n",
    "    dt = DecisionTreeClassifier(max_depth = i)\n",
    "    dt.fit(df_add_treino.drop(columns = 'Revenue'),df_add_treino[['Revenue']])\n",
    "    \n",
    "    x_teste = df_add_teste.drop(columns = 'Revenue')\n",
    "    y_teste = df_add_teste[['Revenue']]\n",
    "    \n",
    "    pred = dt.predict(x_teste)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_teste['Revenue'].values, pred).ravel()\n",
    "    \n",
    "    print('Profundidade: ', i)\n",
    "    print('Ácurácia: ',round(asc(pred,y_teste),2))\n",
    "    print('TN, FP, FN, TP: ', tn, fp, fn, tp)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.89219542e-01, 6.54630043e-03, 4.00081591e-03, 1.39040494e-04,\n",
       "       8.38347119e-05, 4.22005099e-06, 1.81958735e-06, 1.53138397e-06,\n",
       "       1.43512582e-06, 7.39683713e-07, 2.64865019e-07, 2.09086322e-07,\n",
       "       1.92214204e-07, 4.40421559e-08, 9.90664399e-09, 9.48551640e-10,\n",
       "       5.00661969e-11])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#realizando PCA para selecionar as principais componentes e talvez excluir a possibilidade de overfitting\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "x_treino = df_add_treino.drop(columns = ['Revenue'])\n",
    "y_treino = df_add_treino[['Revenue']]\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit_transform(x_treino)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vou considerar as 5 primeiras, considerando a ordem de grandeza das variâncias explicadas\n",
    "pca = PCA(n_components = (len(df_add_treino.columns)//3))\n",
    "pca.fit(x_treino)\n",
    "x_treino_transf = pca.transform(x_treino)\n",
    "\n",
    "x_teste = df_add_teste.drop(columns = ['Revenue'])\n",
    "y_teste = df_add_teste[['Revenue']]\n",
    "\n",
    "x_teste_transf = pca.transform(x_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidade:  3\n",
      "Ácurácia:  0.89\n",
      "TN, FP, FN, TP:  1433 132 80 205\n",
      "\n",
      "\n",
      "Profundidade:  4\n",
      "Ácurácia:  0.89\n",
      "TN, FP, FN, TP:  1522 43 165 120\n",
      "\n",
      "\n",
      "Profundidade:  5\n",
      "Ácurácia:  0.89\n",
      "TN, FP, FN, TP:  1495 70 134 151\n",
      "\n",
      "\n",
      "Profundidade:  6\n",
      "Ácurácia:  0.89\n",
      "TN, FP, FN, TP:  1486 79 129 156\n",
      "\n",
      "\n",
      "Profundidade:  7\n",
      "Ácurácia:  0.88\n",
      "TN, FP, FN, TP:  1478 87 130 155\n",
      "\n",
      "\n",
      "Profundidade:  8\n",
      "Ácurácia:  0.88\n",
      "TN, FP, FN, TP:  1486 79 147 138\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(3,9,1):\n",
    "    \n",
    "    dt = DecisionTreeClassifier(max_depth = i)\n",
    "    dt.fit(x_treino_transf,df_add_treino[['Revenue']])\n",
    "\n",
    "    y_teste = df_add_teste[['Revenue']]\n",
    "    \n",
    "    pred = dt.predict(x_teste_transf)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_teste['Revenue'].values, pred).ravel()\n",
    "    \n",
    "    print('Profundidade: ', i)\n",
    "    print('Ácurácia: ',round(asc(pred,y_teste),2))\n",
    "    print('TN, FP, FN, TP: ', tn, fp, fn, tp)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerações\n",
    "\n",
    "Neste caso, esperava-se que com o método PCA a assertividade do modelo fosse maior, porém, tivemos o contrário. \n",
    "Ainda assim, os resultados são satisfatórios. \n",
    "\n",
    "\n",
    "### Considerações finais\n",
    "\n",
    "Para este dataset, os três modelos são eficientes, desde que realizemos as transformações adequadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
